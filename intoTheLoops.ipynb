{"cells":[{"cell_type":"markdown","id":"1c049acc","metadata":{"id":"1c049acc"},"source":["<h1 style=\"font-family: 'Garamond'; color:#084763; font-size: 32px; text-indent: 1em; padding-bottom:3px; border-bottom: solid 2px #3F888F\">intoTheLoops</h1>\n","<p style=\"text-align:justify; text-indent: 1.5em;\">Let us introduce our latest <b>sofware intoTheLoops</b>. In order to reconstruct the creation process and the role of its components, the presentation of the software is articulated according to the following structure:</p>\n","<ol>\n","    <li>Introduction to the project's main characters:\n","        <ul>\n","            <li>entities description</li>\n","            <li>data description</li>\n","            <li>data processors &amp; query processors</li>\n","            <li>classes creation</li>\n","        </ul></li>\n","    <li>Relational database: \n","        <ul>\n","            <li>data upload</li>\n","            <li>data query</li>\n","        </ul>\n","    </li>        \n","    <li>Graph database: \n","        <ul>\n","            <li>data upload</li>\n","            <li>data query</li>\n","        </ul>\n","    </li>\n","    <li>Combining results: generic query</li>\n","</ol>\n","<p style=\"text-align:justify; text-indent: 1.5em;\">The main issues of the project will be discussed in a specific box at the end of each paragraph</p>\n","<hr>\n","<h2 style=\"color:#3F888F\">1. Introduction to the project's main characters</h2>\n","<h3 style=\"color:#3F888F; text-indent: 1.5em;\">Entities description</h3>\n","<p style=\"text-align:justify; text-indent: 1.5em;\">The software we are about to introduce is intended to process a number of files of different formats - namely, <b>JSON</b> and <b>CSV</b> - containing several kinds of data about scientific publications. Consequently, the main entities of the whole project are the <b>publications</b> themselves, their <b>authors</b> (i.e., instances of the class <b>Person</b>) and <b>publishers</b> (i.e., instances of the class <b>Organization</b>), and the <b>venues</b> in which the publications have been published. Each of these components belongs to the wide class of <b>identifiable entities</b> and they are all identified by a specifc <b>id</b> (orcid, doi, etc., depending on the entity you are dealing with), as shown in the following UML model.</p> \n","<img src=\"https://raw.githubusercontent.com/comp-data/2021-2022/main/docs/project/datamodel.png\">\n","<p style=\"text-align:center; font-size:12px; color:#333\"><em>Fig.1: the data model of the project's components</em></p><br>\n","<p style=\"text-align:justify; text-indent: 1.5em;\">The UML allows us to understand the main features of each entity and the relationships that exist not only between different classes' intances (e.g.: <em>Publication X</em> has author <em>Person Y</em>), but also inside the same class (e.g. <em>Publication X</em> cites <em>Publication Y</em>). Moreover, it is crucial to recall that the features of each class are inherited by each of the lower level classes. Thus, for example, a Journal instance is expected to have a publicationYear attribute, like its parent class, Publication.</p>\n","<h3 style=\"color:#3F888F; text-indent: 1.5em;\">Data description</h3>\n","<p style=\"text-align:justify; text-indent: 1.5em;\">In the previous paragraph, we stated that the project is intented to process data extracted from JSON files and CSV files. However, the divergence between different files is not only related to the file extension: distinct file formats will be associated with <b>different contents</b>. Let us go into detail. CSV files are expected to provide the following information: <b>id</b>, <b>title</b>, <b>type</b>, <b>publication_year</b>, <b>issue</b>, <b>volume</b>, <b>chapter</b>, <b>publication_venue</b>, <b>venue_type</b>, <b>publisher</b>, <b>event</b>. This information is not enough to fully describe a publication, thus, we might need to complete this data with some other information exracted from other files. In particular, JSON files provide us with details about the <b>authors</b> (family name, given name, orcid), the <b>venues</b> (venue id), the <b>references</b> (cited publication's doi), and the <b>publishers</b> (crossref id, name). </p><br>\n","<p style=\"text-align:justify; text-indent: 1.5em;\">First, we can immediately recognise how different files are meant to complete each other; then, it is also important to understand how data are structured. A CSV file is based on indexed rows and labeled columns, so that each row tells us some information only about a specific publication that is identified by its DOI.\n","\n","On the other hand, our JSON files contain keys that are four independent blocks: \"authors\", \"venues_id\", \"references\" and \"publishers\". In detail:\n","\n","The keys of the <b> Authors </b> dictionary  are DOIs, each taking a list of dictionaries as value. Each list contains a dictionary whose keys are the \"given\", \"family\", \"orcid\", which contain strings with author data for the specific publication.\n","\n","<b> Venues_id </b> follows a similar structure, but in this case the DOI keys have as values a list that contains the venue identifiers (\"issn\" or \"isbn\").\n","\n","Likewise, each of the <b> References</b> dictionary's keys (which again, are DOIs), take as value a list of the publication identifiers which are cited in that publication.\n","\n","The <b> Publishers </b> dictionary contains multiple dictionaries where each key is the identifier of the publisher (\"crossref: <i> number </i>\"). The keys, as a value, have again a dictionary, that contains data for the id and the corresponding name of the publisher. \n","\n","\n","</p>\n","<h3 style=\"color:#3F888F; text-indent: 1.5em;\">Data processors &amp; query processors</h3>\n","<p style=\"text-align:justify; text-indent: 1.5em;\">Once the nature of our data and entities has been clarified, we are almost ready to start coding. However, some final premises still need to be presented. First, our software must function <b>independently of the file extension and the number of the input documents</b>. Thus, we must create separate paths (<b>methods</b>, whose working will be explained later) for processing data, for uploading them into a database (either a <b>relational</b> one or a <b>graph</b> one), for querying and retrieving information from one or more databases. And finally, <b>what kind of results is the software expected to deliver?</b> What we want to do is providing the software with some input variables (e.g.: 2020 as publication year), which are then processed to retrieve compatible results. The final outputs are <b>python objects</b>, i.e., instances of the mentioned classes (see <em>Entities description</em>, above), whose attributes and methods are better defined by the following UML model:</p>\n","<img src=\"https://github.com/comp-data/2021-2022/raw/main/docs/project/uml.png\">\n","<p style=\"text-align:center; font-size:12px; color:#333\"><em>Fig.2: the UML of data model classes</em></p><br>\n","<h3 style=\"color:#3F888F; text-indent: 1.5em;\">Classes creation</h3>\n","<p style=\"text-align:justify; text-indent: 1.5em;\">Given the last considerations of the previous paragraph, we then need to create a series of <b>python classes</b> to transform the UML into a working software. However, specific classes must be created not only for the entities related to publications, but also for the different type of <b>processors</b> involved in the programme:</p>\n","<img src=\"https://github.com/comp-data/2021-2022/raw/main/docs/project/uml2.png\">\n","<p style=\"text-align:center; font-size:12px; color:#333\"><em>Fig.3: the UML of processors' classes</em></p><br>\n","<p style=\"text-align:justify; text-indent: 1.5em;\">Different classes will be created on separate files, in order to better organize the software components:</p>\n","<ul>\n","    <li><code>DMClasses.py</code>: this file contains the data model (<em>fig.1</em>) classes</li>\n","    <li><code>RelDBClasses.py</code>: this file contains the classes related to the relational database (left side of <em>fig.3</em>)</li>\n","    <li><code>GraDBClasses.py</code>: this file contains the classes related to the graph database (right side of <em>fig.3</em>)</li>\n","</ul>\n","<p style=\"text-align:justify; text-indent: 1.5em;\">All those files are recalled and imported in the main file of the software: <code>intoTheLoops.py</code></p>\n","<hr>\n","<h2 style=\"color:#3F888F\">2. Relational database</h2>\n","<p style=\"text-align:justify; text-indent: 1.5em;\">So far we have introduced some of the software components and file-structure of the project. We have also underlined the crucial role played by classes, which are distributed in several files like the on we are about to introduce. The path we intend to follow starts from documents and ends with python objects. In the middle, the software processes the documents, populates a database using the extracted information, retrieves data from the database and combine them with our databases' data. The file <code>RelDBClasses.py</code> is the one dedicated to the first part of this workflow and contains the following classes:</p>\n","<ul>\n","    <li><code>class <b>RelationalProcessor</b>(object)</code>: it sets and returns the path of the relational database.</li>\n","    <li><code>class <b>RelationalDataProcessor</b><span style=\"color:#8b0000\">(RelationalProcessor)</span></code>: it is a subclass of <b>RelationalProcessor</b> and includes the methods for processing CSV and JSON files and uploading extracted data into the databases.</li>\n","    <li><code>class <b>RelationalQueryProcessor</b><span style=\"color:#8b0000\">(RelationalProcessor)</span></code>: it is a subclass of <b>RelationalProcessor</b> and includes the methods for querying the database. Each query results in a dataframe.</li>\n","</ul>\n","All the methods related to those classes are included in the <em>fig.3</em> UML.\n","<h3 style=\"color:#3F888F; text-indent: 1.5em;\">Data upload</h3>\n","<p style=\"text-align:justify; text-indent: 1.5em;\">At the very beginning, CSV and JSON documents must be processed, thus, we need specific  libraries to access them and better visualize their content:\n","<ol>\n","    <li><code>from <span style=\"color:#8b0000\">pandas</span> import <span style=\"color:#006400\">Series</span>, <span style=\"color:#006400\">DataFrame</span>, <span style=\"color:#006400\">read_csv</span>, <span style=\"color:#006400\">concat</span>, <span style=\"color:#006400\">merge</span></code></li>\n","    <li><code>from <span style=\"color:#8b0000\">json</span> import <span style=\"color:#006400\">load</span></code></li>\n","    <li><code>from <span style=\"color:#8b0000\">sqlite3</span> import <span style=\"color:#006400\">connect</span></code></li>\n","    <li><code>to_sql</code> </li>   \n","</ol>\n","<p style=\"text-align:justify; text-indent: 1.5em;\">The first lines are required in order to access documents (<code>read_csv</code>, <code>load</code>) and manipulate the extracted data by means of <b>pandas DataFrames and Series</b>. <i> Concat</i> and <i> merge</i> are methods of the pandas package that allow us to combine dataframes together. In the case of <i> merge </i>, the combination is based on column values which coexist in our selected dataframes. The following methods refer to the actual work on the database: <code>connect</code> allows us to access the relational database path, and using to_sql, we can upload a created dataframe as a table in our relational database, assign a name for our table, and other parameters we want to specify.</p> \n","\n","\n","  <h4 style=\"color:#3F888F; text-indent: 1.5em\">Issues</h4>\n","  <p> During the upload process, the first crucial task was to populate our database tables <i>independently</i> for each file and to avoid merging dataframes before uploading them to our database, in order to avoid problems. </p>\n","    \n","  <p>Another important issue we faced during the uploading process was the fact that SQLite did not accept list format as values inside the table's rows. To deal with this, we went back to manipulating the data retrieved from the given files. Furthermore, we had to carefully structure our code in order to create the appropriate tables including internal identifiers, in order retrieve all needed information for the instantiation of objects later on. </p>\n","\n","  <h3 style=\"color:#3F888F; text-indent: 1.5em;\">Data query</h3>\n","<ol>\n","  <li> from pandas import read_sql </li>\n","</ol>\n","\n","<p> After having populated our database, we move on to data querying. The methods are defined in the class RelationalQueryProcessor, which implements the <i> read_sql </i> method from pandas that retrieves a dataframe with information according to our SQL query and parameters. \n","<div style=\"background-color:#FAFAFA; border-radius:5px; border:solid 2px #3F888F\">\n","  <h4 style=\"color:#3F888F; text-indent: 1.5em\">Issues</h4>\n","  <p style=\"text-indent: 1.5em\">The main issues we needed to deal with during this stage had to do with the retrieval of specific data that would allow us to pass our resulting dataframes into objects later on. For example, we had to reformulate our queries in order to get one value for publication authors (\"author-id\").</p><br>\n","</div>\n","<br>\n","<hr>\n","<h2 style=\"color:#3F888F\">3. Graph database</h2>\n","<p style=\"text-align:justify; text-indent: 1.5em;\">The general working of this database is very similar to the working of the previous one. The first steps are almost identical, but some crucial distinctions must be taken into account. To be more precise, the main difference between them regards the way their data are stored. In this case, we cannot directly transfer the content of pandas DataFrames into a database. Indeed, we must consider each piece of information as an independent <b>statement</b>, i.e., a sequence of <b>three elements</b>: <b>subject</b>, <b>predicate</b>, <b>object</b>. In order to ease the task related to populating the database, we can use a graph, in which all the <b>triples</b> will be temporarily stored. Moreover, each subject must be associated with a unique identifier (<b>URI</b>), so that it can be recalled multiple times as the subject (sometimes even as the object) of other statements, avoiding misunderstanding.</p> \n","<p style=\"text-align:justify; text-indent: 1.5em;\">We need three different classes (included in the file <code>GraDBClasses.py</code>) to create and query a graph database:</p>\n","<ul>\n","    <li><code>class <b>GraphProcessor</b>(object)</code>: it sets and returns the endpoint of the graph database.</li>\n","    <li><code>class <b>GraphDataProcessor</b><span style=\"color:#8b0000\">(GraphProcessor)</span></code>: it is a subclass of <b>GraphProcessor</b> and includes the methods for processing CSV and JSON files and uploading extracted data into the databases.</li>\n","    <li><code>class <b>GraphQueryProcessor</b><span style=\"color:#8b0000\">(GraphProcessor)</span></code>: it is a subclass of <b>GraphProcessor</b> and includes the methods for querying the database. Each query results in a dataframe.</li>\n","</ul>\n","<p style=\"text-align:justify; text-indent: 1.5em;\">All the methods related to those classes are included in the <em>fig.3</em> UML.</p>\n","\n","<h3 style=\"color:#3F888F; text-indent: 1.5em;\">Data upload</h3>\n","<p style=\"text-align:justify; text-indent: 1.5em;\">What python libraries could help us while dealing with a graph database?</p>\n","<ol>\n","    <li><code>from <span style=\"color:#8b0000\">pandas</span> import <span style=\"color:#006400\">Series</span>, <span style=\"color:#006400\">DataFrame</span>, <span style=\"color:#006400\">read_csv</span>, <span style=\"color:#006400\">merge</span></code></li>\n","    <li><code>from <span style=\"color:#8b0000\">json</span> import <span style=\"color:#006400\">load</span></code></li>\n","    <li><code>from <span style=\"color:#8b0000\">rdflib</span> import <span style=\"color:#006400\">Graph</span>, <span style=\"color:#006400\">URIRef</span>, <span style=\"color:#006400\">Literal</span>, <span style=\"color:#006400\">RDF</span></code></li>\n","    <li><code>from <span style=\"color:#8b0000\">rdflib.plugins.stores.sparqlstore</span> import <span style=\"color:#006400\">SPARQLUpdateStore</span></code></li>\n","    <li><code>from <span style=\"color:#8b0000\">sparql_dataframe</span> import <span style=\"color:#006400\">get</span></code></li> \n","</ol> \n","<p style=\"text-align:justify; text-indent: 1.5em;\">As explained with regard to the relational database, the first two lines are essential in order to access the input documents. In this case, we also need to create a blank graph that is expected to be temporarily populated with a number of triple-statements (line 3). The triples are then moved into our database, whose endpoint (reachable by means of a <b>URL</b>) can be accessed and populated thanks to some specific methods (line 4). In addition, data can be extracted from the database through the function <b>get</b> (line 5).</p><br>\n","<div style=\"background-color:#FAFAFA; border-radius:5px; border:solid 2px #3F888F; padding-left: 15px; padding-right: 15px\">\n","    <h4 style=\"color:#3F888F; text-indent: 1.5em\">Issues</h4>\n","    <p style=\"text-align:justify; text-indent: 1.5em\">One of the main issues you need to deal with during this stage regards the input documents' format and their number. Whenever you upload some data into the database, you must check whether the subject/object of the next triple-statament has already been tackled. E.g.: you upload a JSON file containing some information about the author the publication. Then, you want to upload another file (a CSV one, for instance), which includes some other information about the title of the same publication. You must  inside the current temporary graph and inside th  </p><br>\n","</div>\n","<br>\n","<div style=\"background-color:#FAFAFA; border-radius:5px; border:solid 2px #8b0000; padding-left: 15px; padding-right: 15px\">\n","    <h4 style=\"color:#8b0000; text-indent: 1.5em\">Important!</h4>\n","    <p style=\"text-align:justify; text-indent: 1.5em\">So far, we have generically spoken about an <b>endpoint</b> where the database is located. To be more precise, for this project, we exploited an open-source graph database system written in Java, i.e., <b>Blazegraph</b>. This database system can be installed locally and allows users both to load their own data and to query them using the <b>SPARQL</b> language.</p><br>\n","</div>\n","<br>\n","\n","<h3 style=\"color:#3F888F; text-indent: 1.5em;\">Data querying</h3>\n","<p style=\"text-align:justify; text-indent: 1.5em;\">Once the database has been populated, we are ready to perform some SPARQL queries on the loaded data. Once again, the methods for querying the database correspond to the fig.3 UML and they are all defined inside the <code>class <b>GraphQueryProcessor</b>(GraphProcessor)</code>. The final result of each query is returned as a DataFrame, whose columns' labels correspond to the variables of the SPARQL query.</p><br>\n","<div style=\"background-color:#FAFAFA; border-radius:5px; border:solid 2px #3F888F; padding-left: 15px; padding-right: 15px\">\n","    <h4 style=\"color:#3F888F; text-indent: 1.5em\">Issues</h4>\n","    <p style=\"text-align:justify; text-indent: 1.5em\">One of the main issues you need to deal with during this stage regards the information types you are expected to deal with. Let us pretend that during the data-uploading phase you provided only some JSON documents as input: the software will surely contain some information about some publications (e.g., the doi, the author's family name, etc.), however no data will be available about the publication title. Thus, the software is expected to retrieve some information only when it's possible. This problem can be faced introducing some SPARQL <b>OPTIONAL</b> query modifiers.</p><br>\n","</div>\n","<br>\n","<hr>\n","<h2 style=\"color:#3F888F\">4. Combining results: generic query</h2>\n","<p style=\"text-align:justify; text-indent: 1.5em;\">The queries performed on different databases return several dataframes that need to be merged together in order to get a unique final frame. The databases are indirectly specified by the method <code>addQueryProcessor()</code>: the generic query processor recalls each of the added query processors and performs a certain query on the associated database. The resulting dataframes are combined together and processed, so that the final results are instances of some specific classes, defined on the document <code>DMClasses.py</code>.</p></br>\n","<div style=\"background-color:#FAFAFA; border-radius:5px; border:solid 2px #3F888F; padding-left: 15px; padding-right: 15px\">\n","    <h4 style=\"color:#3F888F; text-indent: 1.5em\">Issues</h4>\n","    <p style=\"text-align:justify; text-indent: 1.5em\">When you perform a query on a database, the resulting dataframe might have a number of rows higher than the number of different items. Let's think about a publication written by three different authors: the dataframe will need three rows for just one publication. Thus, if you want to create an object of the class <code>Publication</code>, you should check if the main item (e.g.: the doi) is included in more than one row.</p><br>"]}],"metadata":{"colab":{"collapsed_sections":[],"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"}},"nbformat":4,"nbformat_minor":5}